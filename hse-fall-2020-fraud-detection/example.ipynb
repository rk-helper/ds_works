{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sTl1xl6pRR5t"
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Iz376nU4RqnN"
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    NAlist = [] # Keeps track of columns that have missing values filled in. \n",
    "    for col in tqdm(df.columns):\n",
    "        if df[col].dtype != object:  # Exclude strings\n",
    "\n",
    "            # make variables for Int, max and min\n",
    "            IsInt = False\n",
    "            col_max_value = df[col].max()\n",
    "            col_min_value = df[col].min()\n",
    "\n",
    "            # Integer does not support NA, therefore, NA needs to be filled\n",
    "            if not np.isfinite(df[col]).all(): \n",
    "                NAlist.append(col)\n",
    "                df[col].fillna(col_min_value - 1, inplace=True)\n",
    "\n",
    "            # test if column can be converted to an integer\n",
    "            col_as_int = df[col].fillna(0).astype(np.int64)\n",
    "            diff = (df[col] - col_as_int)\n",
    "            diff = diff.sum()\n",
    "            if np.abs(diff) < 0.01:\n",
    "                IsInt = True\n",
    "\n",
    "            # Make Integer/unsigned Integer datatypes\n",
    "            if IsInt:\n",
    "                if col_min_value >= 0:\n",
    "                    if col_max_value < 255:\n",
    "                        df[col] = df[col].astype(np.uint8)\n",
    "                    elif col_max_value < 65535:\n",
    "                        df[col] = df[col].astype(np.uint16)\n",
    "                    elif col_max_value < 4294967295:\n",
    "                        df[col] = df[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if col_min_value > np.iinfo(np.int8).min and col_max_value < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif col_min_value > np.iinfo(np.int16).min and col_max_value < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif col_min_value > np.iinfo(np.int32).min and col_max_value < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    elif col_min_value > np.iinfo(np.int64).min and col_max_value < np.iinfo(np.int64).max:\n",
    "                        df[col] = df[col].astype(np.int64)    \n",
    "\n",
    "            # Make float datatypes 32 bit\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "\n",
    "    return df, NAlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "2AEkYpqqRoN1",
    "outputId": "5cbb817f-678d-40bf-b3eb-a96590d34490"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [02:19<00:00,  3.11it/s]\n",
      "100%|██████████| 433/433 [00:54<00:00,  7.98it/s]\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIR = '.'\n",
    "\n",
    "train_transaction = pd.read_csv('train_transaction.csv')\n",
    "train_identity = pd.read_csv('train_identity.csv')\n",
    "test_transaction = pd.read_csv('test_transaction.csv')\n",
    "test_identity = pd.read_csv('test_identity.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "df_train = train_transaction.merge(train_identity, how='left', on='TransactionID')\n",
    "del train_transaction, train_identity\n",
    "df_train, df_train_NAlist = reduce_mem_usage(df_train)\n",
    "\n",
    "df_test = test_transaction.merge(test_identity, how='left', on='TransactionID')\n",
    "del test_transaction, test_identity\n",
    "df_test, df_test_NAlist = reduce_mem_usage(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9erMcVENSZQ8"
   },
   "source": [
    "В данных есть пропуски:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "U07plDYGSVGy",
    "outputId": "54b0f195-3f39-4cf4-a301-69e1393c038c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data in train: 4.47002%\n",
      "Missing data in test: 4.33051%\n"
     ]
    }
   ],
   "source": [
    "print('Missing data in train: {:.5f}%'.format(df_train.isnull().sum().sum() / (df_train.shape[0] * df_train.shape[1]) * 100))\n",
    "print('Missing data in test: {:.5f}%'.format(df_test.isnull().sum().sum() / (df_test.shape[0] * df_test.shape[1]) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZkF-2XcScua"
   },
   "source": [
    "Заполним пропуски в столбцах, где значения выражаются числами - `-1`, а где строками - `'unseen_category'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "xlZJZWIfSbFl",
    "outputId": "7ea360d3-4c7b-49d6-d995-7e9a19804236"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data in train: 0.00000%\n",
      "Missing data in test: 0.00000%\n"
     ]
    }
   ],
   "source": [
    "for col in df_train.columns.drop('isFraud'):\n",
    "    if df_train[col].dtype == 'O':\n",
    "        df_train[col] = df_train[col].fillna('unseen_category')\n",
    "        df_test[col] = df_test[col].fillna('unseen_category')\n",
    "    else:\n",
    "        df_train[col] = df_train[col].fillna(-1)\n",
    "        df_test[col] = df_test[col].fillna(-1)\n",
    "\n",
    "print('Missing data in train: {:.5f}%'.format(df_train.isnull().sum().sum() / (df_train.shape[0] * df_train.shape[1]) * 100))\n",
    "print('Missing data in test: {:.5f}%'.format(df_test.isnull().sum().sum() / (df_test.shape[0] * df_test.shape[1]) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "lmNtdwZYSlFM",
    "outputId": "48cbe44b-237e-4cd2-ccc0-0480a98b61cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 417559 entries, 0 to 417558\n",
      "Columns: 434 entries, TransactionID to DeviceInfo\n",
      "dtypes: float32(80), int16(7), int8(9), object(31), uint16(40), uint32(3), uint8(264)\n",
      "memory usage: 380.3+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 172981 entries, 0 to 172980\n",
      "Columns: 433 entries, TransactionID to DeviceInfo\n",
      "dtypes: float32(78), int16(6), int8(9), object(31), uint16(57), uint32(3), uint8(249)\n",
      "memory usage: 159.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.info(), df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzgpNQeGSnT0"
   },
   "source": [
    "Закодируем категориальные признаки с помощью [`LabelEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) и сконвертируем их в [`category`](https://pandas.pydata.org/pandas-docs/version/0.23.4/categorical.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "VzqHjIi-S4yu",
    "outputId": "69d5e997-912a-43a0-8a75-9778f1833ed2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 433/433 [00:13<00:00, 33.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 417559 entries, 0 to 417558\n",
      "Columns: 434 entries, TransactionID to DeviceInfo\n",
      "dtypes: category(31), float32(80), int16(7), int8(9), uint16(40), uint32(3), uint8(264)\n",
      "memory usage: 294.8 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 172981 entries, 0 to 172980\n",
      "Columns: 433 entries, TransactionID to DeviceInfo\n",
      "dtypes: category(31), float32(78), int16(6), int8(9), uint16(57), uint32(3), uint8(249)\n",
      "memory usage: 123.6 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in tqdm(df_train.columns.drop('isFraud')):\n",
    "    if df_train[col].dtype == 'O':\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(df_train[col]) + list(df_test[col]))\n",
    "        df_train[col] = le.transform(df_train[col])\n",
    "        df_test[col] = le.transform(df_test[col])\n",
    "        \n",
    "        df_train[col] = df_train[col].astype('category')\n",
    "        df_test[col] = df_test[col].astype('category')\n",
    "\n",
    "df_train.info(), df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0jnIH1iS7xE"
   },
   "source": [
    "Перед тем, как обучать какие-либо модели, нужно настроить валидацию - для того, чтобы оценивать обобщающую способность без использования тестовой выборки. Несмотря на то, что модель можно применить к тестовой части и получить результат на лидерборде, отнюдь не факт, что такому результату можно доверять. Дело в том, что он рассчитывается по публичной части тестовой выборки - однако итоговый результат будет рассчитываться по приватной части после окончания соревнования. Распределение данных в публичной и приватной частях может различаться, и если вы будете оценивать качество только по результату на публичной части, может получиться так, что ваше итоговое место в соревновании будет сильно ниже того, что вы имели по ходу.\n",
    "\n",
    "Однако бывают случаи, когда можно занять топовые места в соревновании и без настройки валидации, доверяя лишь результату на публичной части тестовой выборки. Пример: [описание решения победителя соревнования по детекции диабетической ретинопатии](https://www.kaggle.com/c/aptos2019-blindness-detection/discussion/108065).\n",
    "\n",
    "Техники валидации могут быть очень разными - от разбиения на обучающую/валидационную часть до [разбиения на группы с перемешиванием](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupShuffleSplit.html#sklearn.model_selection.GroupShuffleSplit). Для кросс-валидации может быть полезно воспользоваться модулем [cross_validation](https://scikit-learn.org/stable/modules/cross_validation.html) из библиотеки `scikit-learn`.\n",
    "\n",
    "Настройка корректной валидации очень зависит от поставленной задачи. Очевидно, в идеале нужно выбрать такой способ, который сможет отразить то, насколько хорошо модель справится с приватной частью тестовой выборки.\n",
    "\n",
    "В ноутбуке с EDA было выдвинуто следующее предположение: согласно поведению признака `TransactionDT`, в обучающей части выборки содержатся данные за 4 месяца. Давайте настроим кросс-валидацию с 4 фолдами, где в каждом случае будем брать в качестве валидационной части тот или иной месяц."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "JRxrhtG2S5fc",
    "outputId": "7ba907a0-c386-43bc-ec96-10ed191d9cb6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120.99996527777778"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_train['TransactionDT'].max() - df_train['TransactionDT'].min()) / (3600 * 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "RYxCoXhsS9t0",
    "outputId": "8eca57c8-88c4-4344-cadf-4c69faa22e50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417559,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_length = 3600 * 24 * 30\n",
    "df_train['TransactionDT'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "L0wcKf28S-sl",
    "outputId": "4b0e1fbd-cfea-4a87-c105-503cb0f6038f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set 0 length: 134339\n",
      "Validation set 1 length: 89399\n",
      "Validation set 2 length: 92189\n",
      "Validation set 3 length: 101632\n"
     ]
    }
   ],
   "source": [
    "fold0_idx = df_train[df_train['TransactionDT'] < df_train['TransactionDT'].min() + month_length].index\n",
    "fold1_idx = df_train[(df_train['TransactionDT'].min() + month_length <= df_train['TransactionDT']) & (df_train['TransactionDT'] < df_train['TransactionDT'].min() + 2 * month_length)].index\n",
    "fold2_idx = df_train[(df_train['TransactionDT'].min() + 2 * month_length <= df_train['TransactionDT']) & (df_train['TransactionDT'] < df_train['TransactionDT'].min() + 3 * month_length)].index\n",
    "fold3_idx = df_train[df_train['TransactionDT'].min() + 3 * month_length <= df_train['TransactionDT']].index\n",
    "print('Validation set 0 length:', len(fold0_idx))\n",
    "print('Validation set 1 length:', len(fold1_idx))\n",
    "print('Validation set 2 length:', len(fold2_idx))\n",
    "print('Validation set 3 length:', len(fold3_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RNfmDyDFS_uk"
   },
   "outputs": [],
   "source": [
    "folds_idx = [fold0_idx, fold1_idx, fold2_idx, fold3_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "rqh9jT1zTAv8",
    "outputId": "3416bca9-8c00-45d2-d351-8fec31f0c51f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 1, 0, 3, 2]\n",
       "Categories (5, int64): [4, 1, 0, 3, 2]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(df_train['ProductCD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qs_WuPygTDa8"
   },
   "source": [
    "В данных есть признак-идентификатор объекта - `'TransactionID'`. Заметим, что его значения в обучающей и тестовых выборках не пересекаются:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "6H9SAbaJTBqs",
    "outputId": "b133c398-c6b2-42b1-bd0d-51a862007717"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_train['TransactionID']).intersection(set(df_test['TransactionID']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UeIe6SnmTF1F"
   },
   "source": [
    "Также не пересекаются значения признака, отвечающего за момент времени - `'TransactionDT'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "LrUbzPCATEhM",
    "outputId": "0e1c258b-eba0-4e2f-9235-6cdf4692ab0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_train['TransactionDT']).intersection(set(df_test['TransactionDT']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZimwAzATLL8"
   },
   "source": [
    "В связи с этим удалим эти признаки, чтобы модель их не учитывала."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "9g5gHNv4THFV",
    "outputId": "35266220-0732-4268-bc3c-4774755a81b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((417559, 432), (172981, 431))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.drop(['TransactionID', 'TransactionDT'], axis=1, inplace=True)\n",
    "df_test.drop(['TransactionID', 'TransactionDT'], axis=1, inplace=True)\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DL6xLvQMTPbl"
   },
   "source": [
    "Обучимся с помощью [`lightgbm`](https://lightgbm.readthedocs.io/en/latest/), и для каждой модели сделаем предсказание на тестовой выборке. Также будем сохранять важности признаков на каждом фолде.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "V2L1Nl5CTMMl",
    "outputId": "966ca33b-9364-4cb7-c357-1da3f3648190",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11320, number of negative: 271900\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.859442\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.764757\n",
      "[LightGBM] [Debug] init for col-wise cost 0.285141 seconds, init for row-wise cost 0.316950 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.300985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 31468\n",
      "[LightGBM] [Info] Number of data points in the train set: 283220, number of used features: 429\n",
      "[LightGBM] [Debug] Use subset for bagging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039969 -> initscore=-3.178863\n",
      "[LightGBM] [Info] Start training from score -3.178863\n",
      "[LightGBM] [Debug] Re-bagging, using 198290 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Re-bagging, using 198503 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Re-bagging, using 198555 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Re-bagging, using 198088 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Re-bagging, using 197848 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Re-bagging, using 198181 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Re-bagging, using 197804 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 23\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Re-bagging, using 198319 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 23\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 198319 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Re-bagging, using 198474 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Re-bagging, using 198697 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Re-bagging, using 197657 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 198132 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 26\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Re-bagging, using 198478 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Re-bagging, using 198429 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Re-bagging, using 197937 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Re-bagging, using 198221 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Re-bagging, using 198650 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Re-bagging, using 198254 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Re-bagging, using 198281 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 23\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 23\n",
      "[100]\tvalid_0's auc: 0.869001\n",
      "[LightGBM] [Info] Number of positive: 11144, number of negative: 317016\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.798186\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.683473\n",
      "[LightGBM] [Debug] init for col-wise cost 0.298739 seconds, init for row-wise cost 0.601440 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.345001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 34278\n",
      "[LightGBM] [Info] Number of data points in the train set: 328160, number of used features: 429\n",
      "[LightGBM] [Debug] Use subset for bagging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.033959 -> initscore=-3.348051\n",
      "[LightGBM] [Info] Start training from score -3.348051\n",
      "[LightGBM] [Debug] Re-bagging, using 229717 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Re-bagging, using 229724 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Re-bagging, using 229998 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Re-bagging, using 229525 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Re-bagging, using 229164 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Re-bagging, using 229823 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Re-bagging, using 229274 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Re-bagging, using 229904 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Re-bagging, using 229718 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Re-bagging, using 230007 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Re-bagging, using 230176 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 27\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Re-bagging, using 229028 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 25\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 23\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Re-bagging, using 229694 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Re-bagging, using 230053 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 25\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 25\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Re-bagging, using 230023 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Re-bagging, using 229605 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Re-bagging, using 229556 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Re-bagging, using 230195 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Re-bagging, using 229638 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Re-bagging, using 229919 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[100]\tvalid_0's auc: 0.892472\n",
      "[LightGBM] [Info] Number of positive: 10997, number of negative: 314373\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.798412\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.683394\n",
      "[LightGBM] [Debug] init for col-wise cost 0.393850 seconds, init for row-wise cost 0.521597 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.424511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 34304\n",
      "[LightGBM] [Info] Number of data points in the train set: 325370, number of used features: 429\n",
      "[LightGBM] [Debug] Use subset for bagging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.033798 -> initscore=-3.352958\n",
      "[LightGBM] [Info] Start training from score -3.352958\n",
      "[LightGBM] [Debug] Re-bagging, using 227769 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Re-bagging, using 227759 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Re-bagging, using 228025 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Re-bagging, using 227556 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 227285 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Re-bagging, using 227845 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Re-bagging, using 227353 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Re-bagging, using 227952 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Re-bagging, using 227733 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 23\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 23\n",
      "[LightGBM] [Debug] Re-bagging, using 228050 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Re-bagging, using 228201 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 23\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Re-bagging, using 227084 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Re-bagging, using 227747 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Re-bagging, using 228098 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 25\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Re-bagging, using 228115 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 25\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Re-bagging, using 227645 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Re-bagging, using 227573 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Re-bagging, using 228249 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Re-bagging, using 227697 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Re-bagging, using 227926 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 23\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[100]\tvalid_0's auc: 0.906273\n",
      "[LightGBM] [Info] Number of positive: 10702, number of negative: 305225\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.794512\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.679682\n",
      "[LightGBM] [Debug] init for col-wise cost 0.357781 seconds, init for row-wise cost 0.890425 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.406846 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 34373\n",
      "[LightGBM] [Info] Number of data points in the train set: 315927, number of used features: 429\n",
      "[LightGBM] [Debug] Use subset for bagging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.033875 -> initscore=-3.350619\n",
      "[LightGBM] [Info] Start training from score -3.350619\n",
      "[LightGBM] [Debug] Re-bagging, using 221173 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 25\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Re-bagging, using 221209 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Re-bagging, using 221419 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 28\n",
      "[LightGBM] [Debug] Re-bagging, using 221010 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Re-bagging, using 220690 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Re-bagging, using 221162 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Re-bagging, using 220778 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 23\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Re-bagging, using 221272 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 23\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Re-bagging, using 221185 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Re-bagging, using 221419 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Re-bagging, using 221624 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 17\n",
      "[LightGBM] [Debug] Re-bagging, using 220499 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 23\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Re-bagging, using 221090 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Re-bagging, using 221431 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Re-bagging, using 221377 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 23\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 23\n",
      "[LightGBM] [Debug] Re-bagging, using 220919 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Re-bagging, using 220967 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 25\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Re-bagging, using 221621 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Re-bagging, using 221120 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[LightGBM] [Debug] Re-bagging, using 221284 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 25\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and max_depth = 20\n",
      "[100]\tvalid_0's auc: 0.889044\n",
      "Fold 0, AUC-ROC: 0.86900\n",
      "Fold 1, AUC-ROC: 0.89247\n",
      "Fold 2, AUC-ROC: 0.90627\n",
      "Fold 3, AUC-ROC: 0.88904\n",
      "CV AUC-ROC: 0.88920\n",
      "CPU times: user 9min 58s, sys: 26.1 s, total: 10min 24s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.01,\n",
    "    'num_leaves': 2**8,\n",
    "    'max_bin': 255,\n",
    "    'max_depth': -1,\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'feature_fraction': 0.7,\n",
    "    'first_metric_only': True,\n",
    "    'verbose': 100,\n",
    "    'n_jobs': -1}\n",
    "\n",
    "scores = []\n",
    "\n",
    "feature_importances = pd.DataFrame()\n",
    "feature_importances['feature'] = df_train.columns.drop('isFraud')\n",
    "\n",
    "test_preds = []\n",
    "for i in range(len(folds_idx)):\n",
    "    X_train = df_train.drop(folds_idx[i], axis=0)\n",
    "    y_train = X_train['isFraud'].values\n",
    "    X_val = df_train.iloc[folds_idx[i]]\n",
    "    y_val = X_val['isFraud'].values\n",
    "    X_train = X_train.drop('isFraud', axis=1)\n",
    "    X_val = X_val.drop('isFraud', axis=1)\n",
    "\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "    lgb_model = lgb.train(params, lgb_train, valid_sets=lgb_eval, verbose_eval=100)\n",
    "    \n",
    "    feature_importances['fold_{}'.format(i)] = lgb_model.feature_importance()\n",
    "\n",
    "    y_pred = lgb_model.predict(X_val)\n",
    "    score_fold = roc_auc_score(y_val, y_pred)\n",
    "    scores.append(score_fold)\n",
    "    y_test_pred = lgb_model.predict(df_test)\n",
    "    test_preds.append(y_test_pred)\n",
    "    \n",
    "\n",
    "for i in range(len(scores)):\n",
    "    print('Fold {}, AUC-ROC: {:.5f}'.format(i, scores[i]))\n",
    "print('CV AUC-ROC: {:.5f}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.11373135, 0.12434962, 0.27214846, ..., 0.11739914, 0.12829628,\n",
       "        0.14941736]),\n",
       " array([0.1118137 , 0.10021471, 0.25503352, ..., 0.07368692, 0.09892523,\n",
       "        0.08978063]),\n",
       " array([0.092617  , 0.0765542 , 0.19079323, ..., 0.06326261, 0.06008122,\n",
       "        0.07328543]),\n",
       " array([0.23238787, 0.12270289, 0.33467485, ..., 0.10666832, 0.10565928,\n",
       "        0.13919368])]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:22:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { missing, n_estimators, subsample=0.8 } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(X_train, y_train, enable_categorical = True)\n",
    "dtest = xgb.DMatrix(X_val, y_val, enable_categorical = True)\n",
    "# specify parameters via map\n",
    "param = {'max_depth':12, 'eval_metric':'auc', 'learning_rate':0.02, 'n_estimators':5000}\n",
    "num_round = 2\n",
    "bst = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction\n",
    "xgb_preds = bst.predict(xgb.DMatrix(df_test, enable_categorical = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjuaHlVwY0uq"
   },
   "source": [
    "Для получения итогового предсказания на тестовой выборке усредним предсказания моделей с разных фолдов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "s_zK4A1sYwza",
    "outputId": "5536f430-9ef9-4cd5-9965-7d45c59d9575"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 172981)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_preds).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 172981)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack([np.array(test_preds), xgb_preds]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "anvL7VKgY1qB",
    "outputId": "4221e8c6-8d80-48d2-9268-f33574364f19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13763748, 0.10595536, 0.26316252, ..., 0.09025425, 0.0982405 ,\n",
       "       0.11291928])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred = 1*np.average(test_preds, axis=0)+0*xgb_preds\n",
    "final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "Z-LPStWaY2bK",
    "outputId": "b94ea65d-47e3-4303-9c61-2c071f140985"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3404559</td>\n",
       "      <td>0.149195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3404560</td>\n",
       "      <td>0.117672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3404561</td>\n",
       "      <td>0.270899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3404562</td>\n",
       "      <td>0.184097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3404563</td>\n",
       "      <td>0.126944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID   isFraud\n",
       "0        3404559  0.149195\n",
       "1        3404560  0.117672\n",
       "2        3404561  0.270899\n",
       "3        3404562  0.184097\n",
       "4        3404563  0.126944"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.DataFrame({'TransactionID': sample_submission['TransactionID'], 'isFraud': final_pred})\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "7gy2H_XkY4JZ",
    "outputId": "f469a6f7-dd95-4dd9-9341-9e4e086e2412"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172976</th>\n",
       "      <td>3577535</td>\n",
       "      <td>0.103903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172977</th>\n",
       "      <td>3577536</td>\n",
       "      <td>0.109705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172978</th>\n",
       "      <td>3577537</td>\n",
       "      <td>0.102488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172979</th>\n",
       "      <td>3577538</td>\n",
       "      <td>0.109888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172980</th>\n",
       "      <td>3577539</td>\n",
       "      <td>0.124211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TransactionID   isFraud\n",
       "172976        3577535  0.103903\n",
       "172977        3577536  0.109705\n",
       "172978        3577537  0.102488\n",
       "172979        3577538  0.109888\n",
       "172980        3577539  0.124211"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpK7-FSkgQ4Y"
   },
   "source": [
    "Сохраняем файл с предсказаниями - теперь его можно отправить в соревнование и посмотреть результат на публичной части."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "VZaOYJR5ZDY1"
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submission_xgb4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVVBk2XoZBA0"
   },
   "source": [
    "Наконец, построим распределение предсказаний для целевой переменной на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "59JXv7XLZCEw",
    "outputId": "51cc4ef6-b802-4b19-aa57-ffc38f29f905"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 8))\n",
    "plt.hist(sub['isFraud'], bins=30)\n",
    "plt.title('Distribution of isFraud prediction on test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', 'M1',\n",
       "       'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'id_12', 'id_15',\n",
       "       'id_16', 'id_23', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_33',\n",
       "       'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType',\n",
       "       'DeviceInfo'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.select_dtypes(include=['category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', 'M1',\n",
       "       'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'id_12', 'id_15',\n",
       "       'id_16', 'id_23', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_33',\n",
       "       'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType',\n",
       "       'DeviceInfo'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.select_dtypes(include=['category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_preds = model.predict(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92189,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.526616968437031"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(np.array(y_val), cat_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "fraud-baseline-lightgbm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
